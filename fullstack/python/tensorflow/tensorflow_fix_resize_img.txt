#######################################################
#
#   FIX Warnings
#
#######################################################

//  replace FastGFile with GFile

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
0 = all messages are logged (default behavior)
1 = INFO messages are not printed
2 = INFO and WARNING messages are not printed
3 = INFO, WARNING, and ERROR messages are not printed
// set Debug Level to 3

import os
os.environ['TF_CPP_MIN_LOG_LEVEL']='3'
#os.environ['TF_CPP_MIN_VLOG_LEVEL']='3'
import tensorflow as tf

----------------------------------------------
// resize img ...
// models/tutorials/image/imagenet/classify_image.py

"""
# pip3 install scikit-image
# sudo pip3 install opencv-contrib-python
# pip3 install Pillow

# sudo apt-get install python-matplotlib python-numpy python-pil python-scipy
# sudo apt-get install build-essential cython
# sudo apt install python-skimage
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import os.path
import re
import sys
import tarfile
import cv2

os.environ['TF_CPP_MIN_LOG_LEVEL']='3'

import PIL
from PIL import Image, ImageOps

from skimage import io
from skimage.transform import resize
from skimage import data, color
from skimage.transform import rescale, resize, downscale_local_mean

import numpy as np
from six.moves import urllib
import tensorflow as tf



# pylint: disable=line-too-long
DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz' # 88931400 bytes / 88Mb
#DATA_URL = 'http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz' # 171177982 bytes / 171Mb
# pylint: enable=line-too-long




def run_inference_on_image(image):
  ...


# pip3 install tensorflow
image_data = tf.gfile.GFile(image, 'rb').read()
predictions = sess.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data})


# pip3 install Pillow
from PIL import Image
imager = Image.open(image)
size = 156, 156
imager.thumbnail(size)
image_data = np.array(imager)[:, :, 0:3]  # Select RGB channels only.
predictions = sess.run(softmax_tensor, {'DecodeJpeg:0': image_data})


# pip install opencv-python
import cv2
imager = cv2.imread(image)
height, width = imager.shape[:2]
newimg = cv2.resize(imager,  None, fx = 0.2, fy = 0.2)
image_data = np.array(newimg)[:, :, 0:3]
#cv2.imshow("Shrinked image", image_data)
#cv2.waitKey(0)
#cv2.destroyAllWindows()
predictions = sess.run(softmax_tensor, {'DecodeJpeg:0': image_data})




############################################################
#
# displaying flow operations
#
############################################################


# print operations
for i in tf.get_default_graph().get_operations():
    print (i.name)

"""
# read pb into graph_def
with tf.gfile.GFile('classify_image_graph_def.pb', "rb") as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())

# import graph_def
with tf.Graph().as_default() as graph:
    tf.import_graph_def(graph_def)

# print operations
for op in graph.get_operations():
    print(op.name)
"""


############################################################
#
# using gpu flow operations
#
############################################################


#with tf.device("/cpu:0"):
with tf.device("/gpu:0"):

  # Setup operations
  #config = tf.ConfigProto(device_count = {'GPU': 1})
  #gpu_options = tf.GPUOptions(visible_device_list="0")
  #config=tf.ConfigProto(log_device_placement=True)
  #with tf.Session(config=config) as sess:

  with tf.Session() as sess:
  #with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
  #with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:

    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0') # pool_3:0 softmax:0
    pool_3 = sess.graph.get_tensor_by_name('pool_3:0')
    predictions , pool3_val = sess.run([softmax_tensor, pool_3], {'DecodeJpeg:0': image_data})
    predictions = np.squeeze(predictions)



############################################################
#
#   Bilderkennung mit Tensorflow in Ubuntu 17.04/18.04/19.04
#
############################################################
// Usage with Python API Tensorflow


Step1 . Install Dependency Packages

sudo apt install python3-pip -y
pip3 install tensorflow
pip3 install numpy
pip3 install pandas


Step2. Install Models f√ºr Tensorflow
git clone https://github.com/tensorflow/models
cd models/tutorials/image/imagenet

Step3. Run Python Script
python3 classify_image.py --image_file ~/Downloads/palm_baby/baby2.jpg

Output:
toilet tissue, toilet paper, bathroom tissue (score = 0.14066)
paper towel (score = 0.05858)
handkerchief, hankie, hanky, hankey (score = 0.04211)
groom, bridegroom (score = 0.04065)
pajama, pyjama, pj's, jammies (score = 0.03977)


FIX Allocation of 9782001216 exceeds 10% of system memory
pip install h5py==2.8.0rc1
go to model/research/slim and run the following: `pip install -e .`

############################################################
#
#   Bilderkennung mit Yolo in Ubuntu 17.04/18.04/19.04
#
############################################################

Step1. Yolo Installation
git clone https://github.com/pjreddie/darknet.git
cd darknet
make


Step2. Get Yolo Training Models
wget https://pjreddie.com/media/files/yolov3.weights
wget https://pjreddie.com/media/files/yolo.weights
wget https://pjreddie.com/media/files/yolov2.weights
wget https://pjreddie.com/media/files/yolo-tiny.weights

Step3. Detection Using A Pre-Trained Model
./darknet detect cfg/yolov3.cfg yolov3.weights  ~/Downloads/palm_baby/baby1.jpg -out baby1_prediction.jpg

output
baby1.jpg: Predicted in 8.617667 seconds.

person: 82%
person: 64%
person: 55%




---------------------------------------
check the TensorRT version on your environment:

dpkg -l | grep nvinfer
dpkg -l | grep cuda

# For CPU
pip install tensorflow
# For GPU
pip install tensorflow-gpu

from utils import label_map_util
from utils import visualization_utils as vis_util


python3 export_inference_graph.py \
    --input_type image_tensor \
    --pipeline_config_path training/ssd_mobilenet_v1_pets.config \
    --trained_checkpoint_prefix training/model.ckpt-10856 \
    --output_directory mac_n_cheese_inference_graph









